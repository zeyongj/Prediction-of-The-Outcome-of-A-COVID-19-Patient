"""“CMPT459 - Colab.ipynb”

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kyAN_8OK2ZXiDgQ7IvyvjXM2bcv8prYh
"""

import pandas as pd
import numpy as np
import os

individual_data = pd.read_csv('../data/cases_train.csv')
individual_test = pd.read_csv('../data/cases_test.csv')
location_data = pd.read_csv('../data/location.csv')


"""# 1.2 Data cleaning and Imputing missing values"""
"""# methods concerning missing value learned from : https://blog.csdn.net/sinat_28442665/article/details/104901143
    # methods concerning ages learned from: https://zhuanlan.zhihu.com/p/166597513, https://www.runoob.com/python/python-strings.html
    # methods concerning dates format learned from: https://www.cnblogs.com/sunshine-blog/p/8477893.html"""
def modify_dates(example):
  try:
    if '-' in example:
      return pd.to_datetime(example.split('-')[0], dayfirst = True)
    else:
      return pd.to_datetime(example,dayfirst = True)
  except:
    return np.nan
individual_data['date_confirmation'] = individual_data['date_confirmation'].apply(modify_dates)
individual_test['date_confirmation'] = individual_test['date_confirmation'].apply(modify_dates)

def modify_ages(example):
    try:
        return pd.to_numeric(example)
    except:
        if '+' in example:
            return int(example.split('+')[0])
        elif '-' in example:
            try:
                return np.mean([int(i) for i in example.split('-')])
            except:
                return int(example.split('-')[0])
        else:
            return int(example.split()[0])/12.
individual_data['age'] = individual_data['age'].apply(modify_ages)
individual_test['age'] = individual_test['age'].apply(modify_ages)
fillnum = individual_data['age'].mean()
individual_data['age'].fillna(fillnum,inplace=True)
fillnum = individual_test['age'].mean()
individual_test['age'].fillna(fillnum,inplace=True)


"""# 1.3 Dealing with outliers"""

location_data = location_data.dropna(subset=['Lat', 'Long_'])
location_data = location_data.drop(location_data[(location_data.Lat < -90) | (location_data.Lat > 90) | (location_data.Long_ < -180) | (location_data.Long_ > 180)].index)
individual_data = individual_data.dropna(subset=['latitude', 'longitude'])
individual_data = individual_data.drop(individual_data[(individual_data.age > 110) | (individual_data.age < 0)].index)
individual_data = individual_data.drop(individual_data[(individual_data.latitude < -90) | (individual_data.latitude > 90) | (individual_data.longitude < -180) | (individual_data.longitude > 180)].index)



"""# 1.4 Transformation
#Some ideas borrowed from : https://github.com/alhparsa/CMPT459-Project/blob/main/Milestone_1.ipynb
"""

usLocation = location_data[location_data['Country_Region'] == 'US']
states = usLocation['Province_State'].unique()
weighted_latitude = []
weighted_longitude = []
incidence_rates = []
fatality_rates = []
keys = []
confirm_sum = []
death_sum = []
recover_sum = []
active_sum = []
for state in states:
  confirmed = deaths = recovered = active = incidence_rate = case_fatality = ratio = population = 0
  temp = location_data[location_data['Province_State'] == state]
  count1 = (temp['Confirmed']*temp['Lat']).sum()
  count2 = (temp['Confirmed']*temp['Long_']).sum()
  loc = temp['Confirmed'].sum()
  total1 = count1/loc
  total2 = count2/loc
  weighted_latitude.append(total1)
  weighted_longitude.append(total2)
  for i in range(0, usLocation.shape[0]):
    us = usLocation.iloc[i]
    if us['Province_State'] == state:
      confirmed += us['Confirmed']
      deaths += us['Deaths']
      recovered += us['Recovered']
      active += us['Active']
      ratio = us['Incidence_Rate']
      if ratio==0:
        continue
      population += (us['Confirmed']*100000)/ratio
  incidence_rate=(confirmed*100000)/population
  case_fatality=(deaths/confirmed)*100
  confirm_sum.append(confirmed)
  death_sum.append(deaths)
  recover_sum.append(recovered)
  active_sum.append(active)
  incidence_rates.append(incidence_rate)
  fatality_rates.append(case_fatality)
  key = state + ", US"
  keys.append(key)
temp = usLocation['Last_Update'].unique()
last_update = temp[0]
location_trans = pd.DataFrame({'state':states, 'country': 'United States', 'Last_Update': last_update, 'Lat':weighted_latitude, 'Long_':weighted_longitude, 'Confirmed': confirm_sum, 'Deaths': death_sum, 'Recovered': recover_sum, 'Active': active_sum, 'Combined_Key': keys, 'Incidence_Rate': incidence_rates, 'Case-Fatality_Ratio': fatality_rates },)
if os.path.exists('../results') == False:
    os.makedirs('../results')
location_trans.to_csv('../results/location_transformed.csv', index=False)

"""# 1.5 Joining the cases and location dataset"""

join_train = pd.merge(individual_data,location_data,left_on=['province','country'],right_on = ['Province_State','Country_Region'])
join_train.drop(['Lat', 'Long_','Province_State','Country_Region'],axis=1,inplace=True)
join_train.to_csv('../results/case_train_processed.csv', index=False)
join_test = pd.merge(individual_test,location_data,left_on=['province','country'],right_on = ['Province_State','Country_Region'])
join_test.drop(['Lat', 'Long_','Province_State','Country_Region'],axis=1,inplace=True)
join_test.to_csv('../results/case_test_processed.csv', index=False)